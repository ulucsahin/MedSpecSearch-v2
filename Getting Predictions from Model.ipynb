{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to get predictions from a model (same procedure for both trained or restored). In this notebook predictions from a restored model is used.\n",
    "\n",
    "Note that you do not need this notebook to use modules. This notebook is just for displaying the usage of them. To make it easier to understand.<br>\n",
    "<br><br>\n",
    "Index of this notebook:<br>\n",
    "1- Hyperparameters and initial setup <br>\n",
    "2- Loading embedding model<br>\n",
    "3- Restoring pre-trained model<br>\n",
    "4- Getting predictions <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dermatology': 'Deri ve Zührevi Hastalıkları (Cildiye)', 'Internal Medicine': 'İç Hastalıkları (Dahiliye)', 'Neurology': 'Nöroloji', 'Obstetrics & Gynecology': 'Kadın Hastalıkları ve Doğum', 'Ophthalmology': 'Göz Hastalıkları', 'Orthopaedic Surgery': 'Ortopedi ve Travmatoloji', 'Otolaryngology': 'Kulak Burun Boğaz Hastalıkları', 'Pediatrics': 'Çocuk Sağlığı ve Hastalıkları', 'Psychiatry': 'Ruh Sağlığı ve Hastalıkları', 'Radiology-Diagnostic': 'Radyoloji', 'Surgery-General': 'Genel Cerrahi', 'Urology': 'Üroloji'}\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "import EmbedHelper\n",
    "import DataLoader\n",
    "import Models\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Hyperparameters and initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Fast Text', 2: 'Google News', 3: 'HealthTap', 4: 'Pubmed', 5: 'Glove', 6: 'iCliniq Trigram', 7: 'iCliniq default'}\n"
     ]
    }
   ],
   "source": [
    "embedDict = EmbedHelper.EmbeddingHandler.embedDict\n",
    "print(embedDict)\n",
    "configs = {\n",
    "    \"vectorSize\":300,\n",
    "    \"trainNewModel\":True,\n",
    "    \"dataColumn\":\"question\",\n",
    "    \"maxLength\":128,\n",
    "    \"batchSize\":8,\n",
    "    \"embeddingType\":embedDict[2],\n",
    "    \"PreEmbed\":True,\n",
    "    \"restore\":True,\n",
    "    \"model_type\":\"CNN_3Layer\" # Options are : \"CNN\" (1 layer) , \"CNN_3Layer\", \"RNN_LSTM\"\n",
    "}\n",
    "\n",
    "inputSize = configs[\"maxLength\"]\n",
    "vectorSize = configs[\"vectorSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Loading embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Google News\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "EmbedModel = EmbedHelper.EmbeddingHandler(configs[\"embeddingType\"], False, 300, \"Embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Restoring pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "fullvectorsize:  300\n",
      "WARNING:tensorflow:From E:\\Code\\Python\\MedSpecSearch-v2-master\\Models.py:250: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 126, 1, 250)\n",
      "WARNING:tensorflow:From E:\\Code\\Python\\MedSpecSearch-v2-master\\Models.py:271: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From E:\\Code\\Python\\MedSpecSearch-v2-master\\Models.py:279: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From E:\\Code\\Python\\MedSpecSearch-v2-master\\Models.py:305: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from NNModels/test_model_name/CNN_3Layermodel.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Remember that we used \"test_model_name\" when saving our model. Now we restore that model.\n",
    "model_name = \"test_model_name\"\n",
    "\n",
    "# Specify model path.\n",
    "model_path = \"NNModels/\" + model_name + \"/\"+ configs[\"model_type\"] + \"model.ckpt\"\n",
    "\n",
    "# Output size 12 since we have 12 classes in data.\n",
    "outputSize = 12\n",
    "\n",
    "if configs[\"model_type\"] == \"CNN\":\n",
    "    nnModel = Models.CNN(inputSize=inputSize, vectorSize=vectorSize, outputSize=outputSize)\n",
    "elif configs[\"model_type\"] == \"CNN_3Layer\":\n",
    "    nnModel = Models.CNN_3Layer(inputSize=inputSize, vectorSize=vectorSize, outputSize=outputSize)\n",
    "elif configs[\"model_type\"] == \"RNN_LSTM\":\n",
    "    nnModel = Models.RNN_LSTM(inputSize=inputSize, vectorSize=vectorSize, outputSize=outputSize)\n",
    "\n",
    "# Create session and assign model graph.\n",
    "sess = tf.InteractiveSession(graph=nnModel.paperGraph)\n",
    "\n",
    "# Initialize variables.\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(tf.tables_initializer())\n",
    "\n",
    "# Restore the saved model.\n",
    "tf.train.Saver().restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Getting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example input, this can also be read from a file as text and put in array.\n",
    "raw_user_input = [\"Hello doctor, I have itchy skin problem.\"]\n",
    "\n",
    "# Processing input so it can be fed into model.\n",
    "user_input = DataLoader.DataHandler.cleanTextData(raw_user_input)\n",
    "user_input = np.array(DataLoader.DataHandler.textIntoWordList(user_input, 128)[0])\n",
    "\n",
    "# Getting the results which contains prediction.\n",
    "results = helper.evaluatePerformance(configs, nnModel, EmbedModel, sess, user_input, [], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get our prediction from results.\n",
    "prediction = helper.get_prediction_single_input(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dermatology\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall accuracy if more than one data instance is evaluated\n",
    "# suitable for testing accuracy over a dataset\n",
    "# Would not work if there is no target data.\n",
    "print(results[\"Accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
