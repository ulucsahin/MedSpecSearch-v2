{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook computes phrases in data and replaces words with phrases. Also trains a new Word2Vec embeddings upon those phrased data.\n",
    "\n",
    "Use either \"Prepare Data 20news\" part or \"Prepare data fold0\" part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import gensim\n",
    "import newsgroups\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utility\n",
    "import pickle\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data 20news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, trainTarget, testData, testTarget, class_dict, reverse_class_dict = newsgroups.process_newsgroups_numpy(True,False,True,False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_fetch = True\n",
    "should_save = True\n",
    "should_read = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_fetch:\n",
    "    # Fetch data\n",
    "    raw_data_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "    target_names = raw_data_train.target_names\n",
    "    raw_data_train = pd.DataFrame([raw_data_train.data, raw_data_train.target.tolist()]).T\n",
    "    raw_data_train.columns = ['text', 'target']\n",
    "\n",
    "    raw_data_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "    raw_data_test = pd.DataFrame([raw_data_test.data, raw_data_test.target.tolist()]).T\n",
    "    raw_data_test.columns = ['text', 'target']\n",
    "\n",
    "if should_save:\n",
    "    raw_data_train.to_csv(\"lol_train.csv\")\n",
    "    raw_data_test.to_csv(\"lol_test.csv\")\n",
    "\n",
    "if should_read:\n",
    "    # Read data\n",
    "    trainData = pd.read_csv(\"lol_train.csv\")\n",
    "    testData = pd.read_csv(\"lol_test.csv\")\n",
    "    trainData = trainData.values\n",
    "    testData = testData.values\n",
    "\n",
    "# Remove extra dimension\n",
    "trainData[:,0] = trainData[:,2]\n",
    "trainData = trainData[:,1:3]\n",
    "testData[:,0] = testData[:,2]\n",
    "testData = testData[:,1:3]\n",
    "\n",
    "trainData_raw = trainData\n",
    "testData_raw = testData\n",
    "\n",
    "# Clean Data\n",
    "trainData[:,0] = [utility.clean_str(a).split(\" \") for a in trainData[:,0]]\n",
    "testData[:,0] = [utility.clean_str(a).split(\" \") for a in testData[:,0]]\n",
    "\n",
    "# Split data and labels(Target)\n",
    "trainTarget = trainData[:,1]\n",
    "trainData = trainData[:,0]\n",
    "testTarget = testData[:,1]\n",
    "testData = testData[:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_raw = [utility.clean_str(a) for a in trainData_raw]\n",
    "testData_raw = [utility.clean_str(a) for a in testData_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data fold0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"vectorSize\":300,\n",
    "    \"trainNewModel\":True,\n",
    "    \"dataColumn\":\"question\",\n",
    "    \"maxLength\":400,\n",
    "    \"batchSize\":8,\n",
    "    \"embeddingType\":None,\n",
    "    \"ELMo\":True,\n",
    "    \"PreEmbed\":True,\n",
    "    \"restore\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs converted to numerical forms\n",
      "Input text claned\n",
      "Input text split into tokens and all inputs padded to maximum length\n",
      "Outputs converted to numerical forms\n",
      "Input text claned\n",
      "Input text split into tokens and all inputs padded to maximum length\n"
     ]
    }
   ],
   "source": [
    "dataColumn = \"question\"\n",
    "fold0trainRaw = pandas.read_csv(\"Data/fold_0_train_tr.csv\", encoding=\"utf-8\")\n",
    "fold0testRaw = pandas.read_csv(\"Data/fold_0_test_tr.csv\")\n",
    "fold0trainData = np.hstack((fold0trainRaw[dataColumn].values.reshape(-1,1),fold0trainRaw[\"category2\"].values.reshape(-1,1)))\n",
    "fold0testData = np.hstack((fold0testRaw[dataColumn].values.reshape(-1,1),fold0testRaw[\"category2\"].values.reshape(-1,1)))\n",
    "fold0ClassDict = DataLoader.DataHandler.getUniqueClassMapDict(fold0testData[:,1])\n",
    "\n",
    "    \n",
    "trainData = fold0trainData\n",
    "trainData, trainTarget, _ = DataLoader.DataHandler.masterPreprocessor(trainData,shuffle=True,classDict=fold0ClassDict,maxLength=configs[\"maxLength\"])\n",
    "testData, testTarget, _ = DataLoader.DataHandler.masterPreprocessor(fold0testData,shuffle=True,classDict=fold0ClassDict,maxLength=configs[\"maxLength\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.array(list(trainData)+list(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Phrases (BiGram and TriGram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = all_data\n",
    "# Convert test data to bigram-trigram\n",
    "test_bigram_model = Phraser(Phrases(testData, min_count=10, threshold=100))\n",
    "test_bigram = [test_bigram_model[line] for line in testData]\n",
    "test_trigram_model = Phraser(Phrases(test_bigram, min_count=10, threshold=100))\n",
    "test_trigram = [test_trigram_model[line] for line in test_bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train data to bigram-trigram\n",
    "train_bigram_model = Phraser(Phrases(trainData, min_count=10, threshold=100))\n",
    "# change data with phrases\n",
    "train_bigram = [train_bigram_model[line] for line in trainData]\n",
    "\n",
    "\n",
    "train_trigram_model = Phraser(Phrases(train_bigram, min_count=10, threshold=100))\n",
    "# change data with phrases\n",
    "train_trigram = [train_trigram_model[line] for line in train_bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trigram = np.array(train_trigram)\n",
    "test_trigram = np.array(test_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_trigram = np.vstack((train_trigram, trainTarget)).T\n",
    "test_data_trigram = np.vstack((test_trigram, testTarget)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you do not want to save just change it to false\n",
    "should_save = True\n",
    "if should_save:\n",
    "    pd.DataFrame(train_trigram).to_csv(\"data//icliniq//train_trigram.csv\")\n",
    "    pd.DataFrame(test_trigram).to_csv(\"data//icliniq//test_trigram.csv\")\n",
    "pickle.dump(trainTarget, open( \"data//icliniq//train_trigram_target.pkl\", \"wb\" ))\n",
    "pickle.dump(testTarget, open( \"data//icliniq//test_trigram_target.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "phrases = []\n",
    "for i in range(len(testData)):\n",
    "    for phrase in test_trigram_model[test_bigram[i]]:\n",
    "        if phrase is not \"[None]\" and \"_\" in phrase and phrase not in phrases:\n",
    "            phrases.append(phrase)\n",
    "print(len(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"phrases_icliniq.txt\", \"w\") as f:\n",
    "    for item in phrases:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change encoding (there may be error otherwise)\n",
    "for i in range(len(test_trigram)):\n",
    "    test_trigram[i] = [a.encode(\"utf-8\") for a in test_trigram[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word2Vec with phrased data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172539, 28712000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = [list(a) for a in all_data] \n",
    "data = all_data\n",
    "w2v_model = gensim.models.Word2Vec(data,size=300, window=10, min_count=2,workers=10)\n",
    "w2v_model.train(data, total_examples=len(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.save(\"Embeddings//icliniq_default//icliniq_default.w2v\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
