{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook computes phrases in data and replaces words with phrases. Also trains a new Word2Vec embeddings upon those phrased data.\n",
    "\n",
    "Use either \"Prepare Data 20news\" part or \"Prepare data fold0\" part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import gensim\n",
    "import newsgroups\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utility\n",
    "import pickle\n",
    "import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data 20news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is ready to be fed into neural network\n",
    "# Can be used to create phrases aswell\n",
    "trainData, trainTarget, testData, testTarget, class_dict, reverse_class_dict = newsgroups.process_newsgroups_numpy(True,False,True,False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data fold0(iCliniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"vectorSize\":300,\n",
    "    \"trainNewModel\":True,\n",
    "    \"dataColumn\":\"question\",\n",
    "    \"maxLength\":400,\n",
    "    \"batchSize\":8,\n",
    "    \"embeddingType\":None,\n",
    "    \"PreEmbed\":True,\n",
    "    \"restore\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs converted to numerical forms\n",
      "Input text claned\n",
      "Input text split into tokens and all inputs padded to maximum length\n",
      "Outputs converted to numerical forms\n",
      "Input text claned\n",
      "Input text split into tokens and all inputs padded to maximum length\n"
     ]
    }
   ],
   "source": [
    "dataColumn = \"question\"\n",
    "fold0trainRaw = pd.read_csv(\"data/iCliniq/MainCategory-5Fold/fold 0/fold_0_train_tr.csv\", encoding=\"utf-8\")\n",
    "fold0testRaw = pd.read_csv(\"data/iCliniq/MainCategory-5Fold/fold 0/fold_0_test_tr.csv\")\n",
    "fold0trainData = np.hstack((fold0trainRaw[dataColumn].values.reshape(-1,1),fold0trainRaw[\"category2\"].values.reshape(-1,1)))\n",
    "fold0testData = np.hstack((fold0testRaw[dataColumn].values.reshape(-1,1),fold0testRaw[\"category2\"].values.reshape(-1,1)))\n",
    "fold0ClassDict = DataLoader.DataHandler.getUniqueClassMapDict(fold0testData[:,1])\n",
    "\n",
    "trainData = fold0trainData\n",
    "trainData, trainTarget, _ = DataLoader.DataHandler.masterPreprocessor(trainData,shuffle=True,classDict=fold0ClassDict,maxLength=configs[\"maxLength\"])\n",
    "testData, testTarget, _ = DataLoader.DataHandler.masterPreprocessor(fold0testData,shuffle=True,classDict=fold0ClassDict,maxLength=configs[\"maxLength\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Phrases (BiGram and TriGram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.array(list(trainData)+list(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = all_data\n",
    "# Convert test data to bigram-trigram\n",
    "test_bigram_model = Phraser(Phrases(testData, min_count=10, threshold=100))\n",
    "test_bigram = [test_bigram_model[line] for line in testData]\n",
    "test_trigram_model = Phraser(Phrases(test_bigram, min_count=10, threshold=100))\n",
    "test_trigram = [test_trigram_model[line] for line in test_bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train data to bigram-trigram\n",
    "train_bigram_model = Phraser(Phrases(trainData, min_count=10, threshold=100))\n",
    "# change data with phrases\n",
    "train_bigram = [train_bigram_model[line] for line in trainData]\n",
    "\n",
    "\n",
    "train_trigram_model = Phraser(Phrases(train_bigram, min_count=10, threshold=100))\n",
    "# change data with phrases\n",
    "train_trigram = [train_trigram_model[line] for line in train_bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trigram = np.array(train_trigram)\n",
    "test_trigram = np.array(test_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_trigram = np.vstack((train_trigram, trainTarget)).T\n",
    "# test_data_trigram = np.vstack((test_trigram, testTarget)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you do not want to save just change it to false\n",
    "should_save = True\n",
    "if should_save:\n",
    "    pd.DataFrame(train_trigram).to_csv(\"data//phrased//train_trigram.csv\")\n",
    "    pd.DataFrame(test_trigram).to_csv(\"data//phrased//test_trigram.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2137\n"
     ]
    }
   ],
   "source": [
    "phrases = []\n",
    "for i in range(len(testData)):\n",
    "    for phrase in test_trigram_model[test_bigram[i]]:\n",
    "        if phrase is not \"[None]\" and \"_\" in phrase and phrase not in phrases:\n",
    "            phrases.append(phrase)\n",
    "print(len(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data//phrased//phrases_icliniq.txt\", \"w\") as f:\n",
    "    for item in phrases:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change encoding (there may be error otherwise)\n",
    "for i in range(len(test_trigram)):\n",
    "    test_trigram[i] = [a.encode(\"utf-8\") for a in test_trigram[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word2Vec with phrased data and save it to hard drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2v_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-266e2807138e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'w2v_model' is not defined"
     ]
    }
   ],
   "source": [
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15979656, 24122880)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = [list(a) for a in all_data] \n",
    "data = all_data\n",
    "w2v_model = gensim.models.Word2Vec(data, size=300, window=10, min_count=2,workers=10)\n",
    "w2v_model.train(data, total_examples=len(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.save(\"Embeddings//phrased_embedding.w2v\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
